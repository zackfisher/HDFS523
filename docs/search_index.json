[["index.html", "HDFS 523: Strategies for Data Analysis in Developmental Research Chapter 1 About This Book", " HDFS 523: Strategies for Data Analysis in Developmental Research Zachary F. Fisher 2022-01-20 Chapter 1 About This Book This book provides the course notes for HDFS 523. It is currently under development, so any feedback is appreciated (e.g., during class, via email, or the edit link in the header). This first chapter is just about how to use the book – the course content starts in Chapter 2. "],["1.1-why-this-book.html", "1.1 Why this book?", " 1.1 Why this book? There are a few goals of moving from “textbook + slides + exercises” to an ebook. For now, the main goal is to update and integrate code contents from the course into one consistent format, rather than having multiple files to sort through on Canvas. "],["1.2-code-folding.html", "1.2 Code Folding", " 1.2 Code Folding The book combines lecture slides and R coding examples. It is often convenient to hide code when introducing new material. This is accomplished using code folding. An example of code folding is given on this page. Below, a histogram integrated into the text. By clicking on the button called “Show Code” on the top of the page, the R code that produced the histogram will also be visible. Notice that you may need to scroll horizontally to see all of the text in the code window. Also notice that when you hover your mouse over the code window, an icon appears in the top right corner – this lets you copy the block of code with one click. # Here is some R code. You don&#39;t have to look at it when reading the book, but it is here when you need it x &lt;- rnorm(200) hist(x, col = &quot;#4B9CD3&quot;) "],["1.3-acknowledgements.html", "1.3 Acknowledgements", " 1.3 Acknowledgements Many people have contributed to the course materials for HDFS 523. Most importantly, the original R markdown files for the course were developed by Nilam Ram and Zita Oravecz. "],["2-chapter-2.html", "Chapter 2 Data Cleaning", " Chapter 2 Data Cleaning In Chapter 2 we will work through some basic data cleaning operations useful in longitudinal data analysis. The basic idea is provide a set of scripts to use for exploring new repeated measures data sets. "],["2.1-example-data.html", "2.1 Example Data", " 2.1 Example Data For Chapter 2 we will make use of the longitudinal Wechsler Intelligence Scale for Children (WISC; Wechsler, 1949) dataset described by Osborne and Suddick (1972). These data have been detailed extensively in a number of papers (McArdle and Epstein 1987; McArdle 1988; Mcardle and Aber 1990; McArdle and Nesselroade 1994) and are used here with with permission. The WISC data contains repeated measures data from 204 children between the ages of 6 and 11 years old (during grades 6, 7, 9 and 11). Thee repeated measures include component scores for the verbal tests and performance subtests at all four occasions, along with verbal subtest scores for the information, comprehension, similarities, and vocabulary domains at the first and last measurement occasion. The demographics variables mother’s education (continuous in years) and mother graduated high school (dichotomous) are also included. "],["2.2-reading-in-repeated-measures-data.html", "2.2 Reading in Repeated Measures Data", " 2.2 Reading in Repeated Measures Data We can read in the WISC data directly from the QuantDev website. filepath &lt;- &quot;https://quantdev.ssri.psu.edu/sites/qdev/files/wisc3raw.csv&quot; wisc3raw &lt;- read.csv(file=url(filepath), header=TRUE) Additional details on importing different data types into R can be found here: http://www.statmethods.net/input/importingdata.html. "],["2.3-familiarize-yourself-with-the-data.html", "2.3 Familiarize Yourself with the Data", " 2.3 Familiarize Yourself with the Data Let’s take an initial look at the structure of our data object using str() str(wisc3raw) ## &#39;data.frame&#39;: 204 obs. of 20 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ verb1 : num 24.4 12.4 32.4 22.7 28.2 ... ## $ verb2 : num 27 14.4 33.5 28.4 37.8 ... ## $ verb4 : num 39.6 21.9 34.3 42.2 41.1 ... ## $ verb6 : num 55.6 37.8 50.2 44.7 71 ... ## $ perfo1 : num 19.8 5.9 27.6 33.2 27.6 ... ## $ perfo2 : num 23 13.4 45 29.7 44.4 ... ## $ perfo4 : num 43.9 18.3 47 46 65.5 ... ## $ perfo6 : num 44.2 40.4 77.7 61.7 64.2 ... ## $ info1 : num 31.3 13.8 35 24.8 25.3 ... ## $ comp1 : num 25.6 14.8 34.7 31.4 30.3 ... ## $ simu1 : num 22.93 7.58 28.05 8.21 15.98 ... ## $ voca1 : num 22.2 15.4 26.8 20.2 35.4 ... ## $ info6 : num 69.9 41.9 60.4 52.9 67.4 ... ## $ comp6 : num 44.4 44.9 50.3 42.7 86.7 ... ## $ simu6 : num 68 33.9 35.8 45.8 72.4 ... ## $ voca6 : num 51.2 37.7 55.5 36 60.4 ... ## $ momed : num 9.5 5.5 14 14 11.5 14 9.5 5.5 9.5 11.5 ... ## $ grad : int 0 0 1 1 0 1 0 0 0 0 ... ## $ constant: int 1 1 1 1 1 1 1 1 1 1 ... From the output, we can also see that the data frame consists of 204 observations (rows) and 20 variables (columns). Each variable’s name and data type is also listed. Methods like the ones above can be an effective way to initially familiarize yourself with the main features of a dataset. "],["2.4-look-for-duplicated-ids.html", "2.4 Look for Duplicated IDs", " 2.4 Look for Duplicated IDs It is always worth looking for non-unique ID numbers when ID labels are included in a dataset. Here we have an id variable indicating the subject number. Since our data is in a long format (more on that later) duplicate IDs may indicate a potential problem with the data source or clues on how the data is structured. any(duplicated(wisc3raw$id)) ## [1] FALSE "],["2.5-using-table-to-spot-irregularities.html", "2.5 Using table() to Spot Irregularities", " 2.5 Using table() to Spot Irregularities When a variable takes on a limited range of values it is often useful to screen for irregularities or invalid values. This is common across all variable types and can occur for character strings, numeric, integer and factor types. For example, we would expect the grad variable to only take the values of zero or one. We can use the table() function to quickly confirm this. By default table() simply omits any values coded as NA. To include a count of the NA values use the useNA argument of table() as follows: table(wisc3raw$grad, useNA = &quot;always&quot;) ## ## 0 1 &lt;NA&gt; ## 158 46 0 "],["2.6-missing-data.html", "2.6 Missing Data", " 2.6 Missing Data Dealing with missing data in a consistent manner is one of the most important aspects of data cleaning. When data are imported into R it is common to discover missing values are coded according to a variety of conventions. Often a first step in handling missing data involves recoding missing values as NA. Writing bespoke code to handle the different types of missing data one might encounter is tedious and unnecessary. naniar (Tierney et al. 2021) is a useful package with many convenience functions for managing missing data in R. Here we demonstrate some of this functionality. 2.6.1 Generating Example Data Since the WISC data does not contain missing values it is helpful to generate a synthetic dataset containing some commonly encountered missing data codes. set.seed(123) wisc_miss &lt;- wisc3raw wisc_miss$verb1[sample(nrow(wisc_miss),100)] &lt;- -99 wisc_miss$comp1[sample(nrow(wisc_miss),75)] &lt;- &quot;N/A&quot; wisc_miss$info1[sample(nrow(wisc_miss),50)] &lt;- &quot;NA&quot; 2.6.2 Recoding Values with NA Now that we have a dataset with missing values we can use naniar to recode these values to NA. na_strings &lt;- c(&quot;NA&quot;, &quot;N/A&quot;, -99) wisc_miss &lt;- naniar::replace_with_na_all( wisc_miss, condition = ~.x %in% na_strings ) See the naniar vignette on recoding NA values for more detailed information on the package functionality. 2.6.3 Missing Data Visualization Once we have recoded our data in a consistent manner we can use visualizations to explore the missing data. The vis_miss() function from naniar is a good starting point for visualizing the amount of missing data in our dataset. The plots shows the missing values in black and non-missing values in gray. In addition, percentages of missing data in both the dataset and individual variables are provided. naniar::vis_miss(wisc_miss) Many missing data visualizations are described in the naniar vignette on missing data visualization including plots for exploring missing data mechanisms. "],["2.7-exporting-data.html", "2.7 Exporting Data", " 2.7 Exporting Data Depending on work-flow, you may need to export your dataset for use in another statistical software program. The write.csv() function is a convenient method for outputting comma delimited files. write.csv(wisc3raw, file = &quot;wisc3raw.csv&quot;, row.names = FALSE, na = &quot;-99&quot;) Note that by default the write.csv() function will include an extra column of row numbers and will notate missing data with an NA. More information on exporting data is available at http://www.statmethods.net/input/exportingdata.html. "],["2.8-reshaping-repeated-measures-data.html", "2.8 Reshaping Repeated Measures Data", " 2.8 Reshaping Repeated Measures Data Behavioral science tends to use relational data structures - in basic form, spreadsheets. Typically, the data are stored in a data frame (a “fancy” matrix) with multiple rows and columns. Two common schemata used to accommodate repeated measures data are wide format and long format. Different analysis and plotting functions require different kinds of data input. Thus, it is imperative that one can convert the data back and forth between wide and long formats. There are lots of ways to do this. We illustrate one way. Sidebar: The dput() function provides a convenient method to get the variable names (or any R object) into a format that can be read back into R. For example, this can be helpful when working with a long vector of strings. dput(colnames(wisc3raw)) ## c(&quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, ## &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;info1&quot;, &quot;comp1&quot;, &quot;simu1&quot;, &quot;voca1&quot;, &quot;info6&quot;, ## &quot;comp6&quot;, &quot;simu6&quot;, &quot;voca6&quot;, &quot;momed&quot;, &quot;grad&quot;, &quot;constant&quot;) First, let’s subset our data to only include the variables we need for this analysis. var_names_sub &lt;- c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;, &quot;grad&quot; ) wiscraw &lt;- wisc3raw[,var_names_sub] head(wiscraw) ## id verb1 verb2 verb4 verb6 perfo1 perfo2 perfo4 perfo6 momed grad ## 1 1 24.42 26.98 39.61 55.64 19.84 22.97 43.90 44.19 9.5 0 ## 2 2 12.44 14.38 21.92 37.81 5.90 13.44 18.29 40.38 5.5 0 ## 3 3 32.43 33.51 34.30 50.18 27.64 45.02 46.99 77.72 14.0 1 ## 4 4 22.69 28.39 42.16 44.72 33.16 29.68 45.97 61.66 14.0 1 ## 5 5 28.23 37.81 41.06 70.95 27.64 44.42 65.48 64.22 11.5 0 ## 6 6 16.06 20.12 38.02 39.94 8.45 15.78 26.99 39.08 14.0 1 2.8.1 Reshape Wide to Long One way to go from wide to long is using the reshape() function from base R. Notice, the varying argument contains the repeated measures columns we want to stack and the timevar is a new variable containing the grade level information previosuly appended at the end of the colnames listed in varying. # reshape data from wide to long wisclong &lt;- reshape( data = wiscraw, varying = c(&quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;,&quot;verb6&quot;, &quot;perfo1&quot;,&quot;perfo2&quot;,&quot;perfo4&quot;,&quot;perfo6&quot;), timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), direction = &quot;long&quot;, sep = &quot;&quot; ) # reorder by id and day wisclong &lt;- wisclong[ order(wisclong$id, wisclong$grade), ] head(wisclong, 8) ## id momed grad grade verb perfo ## 1.1 1 9.5 0 1 24.42 19.84 ## 1.2 1 9.5 0 2 26.98 22.97 ## 1.4 1 9.5 0 4 39.61 43.90 ## 1.6 1 9.5 0 6 55.64 44.19 ## 2.1 2 5.5 0 1 12.44 5.90 ## 2.2 2 5.5 0 2 14.38 13.44 ## 2.4 2 5.5 0 4 21.92 18.29 ## 2.6 2 5.5 0 6 37.81 40.38 Again, notice how reshape automatically split verb1, verb2, etc. into a string name and a grade variable. 2.8.2 Reshape Long to Wide Now we go from long to wide, again using the reshape() function. The v.names argument specifies the variables to be expanded column wise based on the repeated measure specified in timevar. #reshaping long to wide wiscwide &lt;- reshape( data = wisclong, timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), v.names = c(&quot;verb&quot;,&quot;perfo&quot;), direction = &quot;wide&quot;, sep = &quot;&quot; ) # reordering columns wiscwide &lt;- wiscwide[, c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;,&quot;grad&quot; )] head(wiscwide) ## id verb1 verb2 verb4 verb6 perfo1 perfo2 perfo4 perfo6 momed grad ## 1.1 1 24.42 26.98 39.61 55.64 19.84 22.97 43.90 44.19 9.5 0 ## 2.1 2 12.44 14.38 21.92 37.81 5.90 13.44 18.29 40.38 5.5 0 ## 3.1 3 32.43 33.51 34.30 50.18 27.64 45.02 46.99 77.72 14.0 1 ## 4.1 4 22.69 28.39 42.16 44.72 33.16 29.68 45.97 61.66 14.0 1 ## 5.1 5 28.23 37.81 41.06 70.95 27.64 44.42 65.48 64.22 11.5 0 ## 6.1 6 16.06 20.12 38.02 39.94 8.45 15.78 26.99 39.08 14.0 1 Using functions included in base R can be useful in a number of situations. One example is package development where one may wants to limit dependencies. That said, many people find reshape to be unnecessarily complicated. A similar, and potentially more convenient, set of functions have been developed for reshaping data in the tidyr (Wickham 2021) package. For those interested take a look at the pivot_longer() and pivot_wider() functions. For examples using tidyr to reshape data see the tidyr vignette on pivoting. "],["3-chapter-3.html", "Chapter 3 Describing Longitudinal Data", " Chapter 3 Describing Longitudinal Data In Chapter 3 we will look at some option for describing and visualizing longitudinal data. "],["3.1-example-data-1.html", "3.1 Example Data", " 3.1 Example Data Again we will make use of the WISC data described in Chapter 2. The following commands recreate the wide and long data we will use throughout this chapter. filepath &lt;- &quot;https://quantdev.ssri.psu.edu/sites/qdev/files/wisc3raw.csv&quot; wisc3raw &lt;- read.csv(file=url(filepath),header=TRUE) var_names_sub &lt;- c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;, &quot;grad&quot; ) wiscraw &lt;- wisc3raw[,var_names_sub] # reshaping wide to long wisclong &lt;- reshape( data = wiscraw, varying = c(&quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;,&quot;verb6&quot;, &quot;perfo1&quot;,&quot;perfo2&quot;,&quot;perfo4&quot;,&quot;perfo6&quot;), timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), direction = &quot;long&quot;, sep = &quot;&quot; ) # reorder by id and day wisclong &lt;- wisclong[ order(wisclong$id, wisclong$grade), ] #reshaping long to wide wiscwide &lt;- reshape( data = wisclong, timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), v.names = c(&quot;verb&quot;,&quot;perfo&quot;), direction = &quot;wide&quot;, sep = &quot;&quot; ) # reordering columns wiscwide &lt;- wiscwide[, c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;,&quot;grad&quot; )] "],["3.2-describing-means-and-variances.html", "3.2 Describing Means and Variances", " 3.2 Describing Means and Variances Once the wide and long data sets are in place, we can begin describing and plotting the data. Descriptive statistics and visualization are one of the most important aspects of data analysis. Descriptives and plots will be produced from wide data and long data to show the information that can be gleaned from each construction. Having both in place facilitates learning about the data. Continually keep in mind what portions of the data-box are being described (e.g., persons, variables, occasions). We can do a quick look at descriptives using the describe() function from the psych (Revelle 2021) package. Note the n in both outputs. psych::describe(wiscwide) ## vars n mean sd median trimmed mad min max range skew ## id 1 204 102.50 59.03 102.50 102.50 75.61 1.00 204.00 203.00 0.00 ## verb1 2 204 19.59 5.81 19.34 19.50 5.41 3.33 35.15 31.82 0.13 ## verb2 3 204 25.42 6.11 25.98 25.40 6.57 5.95 39.85 33.90 -0.06 ## verb4 4 204 32.61 7.32 32.82 32.42 7.18 12.60 52.84 40.24 0.23 ## verb6 5 204 43.75 10.67 42.55 43.46 11.30 17.35 72.59 55.24 0.24 ## perfo1 6 204 17.98 8.35 17.66 17.69 8.30 0.00 46.58 46.58 0.35 ## perfo2 7 204 27.69 9.99 26.57 27.34 10.51 7.83 59.58 51.75 0.39 ## perfo4 8 204 39.36 10.27 39.09 39.28 10.04 7.81 75.61 67.80 0.15 ## perfo6 9 204 50.93 12.48 51.76 51.07 13.27 10.26 89.01 78.75 -0.06 ## momed 10 204 10.81 2.70 11.50 11.00 2.97 5.50 18.00 12.50 -0.36 ## grad 11 204 0.23 0.42 0.00 0.16 0.00 0.00 1.00 1.00 1.30 ## kurtosis se ## id -1.22 4.13 ## verb1 -0.05 0.41 ## verb2 -0.34 0.43 ## verb4 -0.08 0.51 ## verb6 -0.36 0.75 ## perfo1 -0.11 0.58 ## perfo2 -0.21 0.70 ## perfo4 0.59 0.72 ## perfo6 0.18 0.87 ## momed 0.01 0.19 ## grad -0.30 0.03 psych::describe(wisclong) ## vars n mean sd median trimmed mad min max range skew ## id 1 816 102.50 58.93 102.50 102.50 75.61 1.00 204.00 203.00 0.00 ## momed 2 816 10.81 2.69 11.50 11.00 2.97 5.50 18.00 12.50 -0.36 ## grad 3 816 0.23 0.42 0.00 0.16 0.00 0.00 1.00 1.00 1.31 ## grade 4 816 3.25 1.92 3.00 3.19 2.22 1.00 6.00 5.00 0.28 ## verb 5 816 30.34 11.86 28.46 29.39 11.33 3.33 72.59 69.26 0.71 ## perfo 6 816 33.99 16.14 33.14 33.34 18.14 0.00 89.01 89.01 0.34 ## kurtosis se ## id -1.20 2.06 ## momed 0.03 0.09 ## grad -0.28 0.01 ## grade -1.43 0.07 ## verb 0.33 0.42 ## perfo -0.43 0.56 3.2.1 Verbal Ability (All Persons and Occasions) Let’s focus on the repeated measures of verbal ability. This step is useful to get a general view of what verbal ability scores look like across persons and occasions, but note that we are ignoring Time. In doing so we are not considering how the repeated measures are nested within individuals. psych::describe(wisclong$verb) ## vars n mean sd median trimmed mad min max range skew kurtosis ## X1 1 816 30.34 11.86 28.46 29.39 11.33 3.33 72.59 69.26 0.71 0.33 ## se ## X1 0.42 In addition to the descriptive statistics we can look at a boxplot of verbal ability scores across persons and occasions. Here we will start to use the ggplot2 (Wickham 2016) package. library(&quot;ggplot2&quot;) ggplot(data = wisclong, aes(x=verb, y=..density..)) + geom_histogram(binwidth=2.5, fill = &quot;white&quot;, color = &quot;black&quot;) + geom_density(color = &quot;red&quot;) + ggtitle(&quot;Verbal Ability Score (across persons and occasions)&quot;) + xlab(&quot;Verbal Ability (Grade 1 to 6)&quot;) + ylab(&quot;Density&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) 3.2.2 Verbal Ability (Across Time) Note that our variable is actually “multivariate” because we have repeated measures. We should really consider the time-dependence when we are looking at descriptive statistics and plots. Let’s now look at verbal ability scores across time collapsed across individuals. This can be done using either the describe() function and the wide data or the describeBy() function and the long data. Let’s look at descriptives using the wide data. psych::describe(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)]) ## vars n mean sd median trimmed mad min max range skew ## verb1 1 204 19.59 5.81 19.34 19.50 5.41 3.33 35.15 31.82 0.13 ## verb2 2 204 25.42 6.11 25.98 25.40 6.57 5.95 39.85 33.90 -0.06 ## verb4 3 204 32.61 7.32 32.82 32.42 7.18 12.60 52.84 40.24 0.23 ## verb6 4 204 43.75 10.67 42.55 43.46 11.30 17.35 72.59 55.24 0.24 ## kurtosis se ## verb1 -0.05 0.41 ## verb2 -0.34 0.43 ## verb4 -0.08 0.51 ## verb6 -0.36 0.75 Identical results can be obtained using the long data. psych::describeBy(wisclong[,c(&quot;verb&quot;)], group = wisclong$grade) ## ## Descriptive statistics by group ## group: 1 ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 204 19.59 5.81 19.34 19.5 5.41 3.33 35.15 31.82 0.13 -0.05 0.41 ## ------------------------------------------------------------ ## group: 2 ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 204 25.42 6.11 25.98 25.4 6.57 5.95 39.85 33.9 -0.06 -0.34 0.43 ## ------------------------------------------------------------ ## group: 4 ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 204 32.61 7.32 32.82 32.42 7.18 12.6 52.84 40.24 0.23 -0.08 0.51 ## ------------------------------------------------------------ ## group: 6 ## vars n mean sd median trimmed mad min max range skew kurtosis ## X1 1 204 43.75 10.67 42.55 43.46 11.3 17.35 72.59 55.24 0.24 -0.36 ## se ## X1 0.75 We can visualize the distribution of verbal scores across grades in a number of different ways. Here we have a histogram. ggplot(data=wisclong, aes(x=verb)) + geom_histogram(binwidth=5, pad = TRUE, fill=&quot;white&quot;, color=&quot;black&quot;) + facet_grid(grade ~ .) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Verbal Ability Score&quot;) + ylab(&quot;Density&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) ## Warning: Duplicated aesthetics after name standardisation: pad We can also create notched boxplots of the within-grade distributions (across individuals). From Wikipedia: Notched box plots apply a notch or narrowing of the box around the median. Notches are useful in offering a rough guide of the significance of the difference of medians; if the notches of two boxes do not overlap, this can provide evidence of a statistically significant difference between the medians. Adding the mean value to the plot gives us additonal information about central tendency and skew of the distribution. #boxplot by grade ggplot(data=wisclong, aes(x=factor(grade), y=verb)) + geom_boxplot(notch = TRUE) + stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, shape=23, size=3, fill=&quot;white&quot;) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + ylab(&quot;Verbal Ability Score&quot;) + xlab(&quot;Grade&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) Finally, we can view overlapping densities of the within-grade distributions of verbal ability scores. ggplot(data=wisclong, aes(x=verb)) + geom_density(aes(group=factor(grade), colour=factor(grade), fill=factor(grade)), alpha=0.3) + guides(colour=&quot;none&quot;, fill=guide_legend(title=&quot;Grade&quot;)) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + ylab(&quot;Density&quot;) + xlab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) Notice in these plots how much “change” there is at the sample level across grades. Is that expected? "],["3.3-describing-covariances.html", "3.3 Describing Covariances", " 3.3 Describing Covariances In the previous section we looked at the means and variances. Because these are repeated measures, we can also look at covariances and correlations over time. A simple covariance and correlation matrix of the verbal scores across grades can be produced using the cov() and cor() function. cov(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)], use=&quot;complete.obs&quot;) ## verb1 verb2 verb4 verb6 ## verb1 33.72932 25.46388 30.88886 40.51478 ## verb2 25.46388 37.28784 33.81957 47.40488 ## verb4 30.88886 33.81957 53.58070 62.25489 ## verb6 40.51478 47.40488 62.25489 113.74332 cor(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)], use=&quot;complete.obs&quot;) ## verb1 verb2 verb4 verb6 ## verb1 1.0000000 0.7180209 0.7265974 0.6541040 ## verb2 0.7180209 1.0000000 0.7566242 0.7279080 ## verb4 0.7265974 0.7566242 1.0000000 0.7974552 ## verb6 0.6541040 0.7279080 0.7974552 1.0000000 A plot corresponding to the correlation matrix can be obtained in a number of different ways. First, using the pairs() function from base R. pairs(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)]) There is also a pairs.panel() function in the psych package. Here we see a LOESS smoothed fit line in red. psych::pairs.panels(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)]) Finally, thescatterplotMatrix() from the car (Fox and Weisberg 2019) package can be used to create scatterplot matrices with confidence bands around the line of best fit. car::scatterplotMatrix(~ verb1 + verb2 + verb4 + verb6, data=wiscwide) Each of these functions can be customized with additional features. Those interested in specifics should consult the help documentation for each function (e.g. ?car::scatterplotMatrix). It is also worth noting the default behavior of these functions is to provide automatic, data-based ranges for each pair of variables separately. "],["3.4-individual-level-descriptives.html", "3.4 Individual-Level Descriptives", " 3.4 Individual-Level Descriptives Note that our interest is often in individual development, rather than sample development. We need to consider how each individual is changing over time. Thus, we are interested in verbal ability across Time for each individual person. Visualization is typically our best tool for synthesizing the large amounts of information in individual-level data. ggplot(data = wisclong, aes(x = grade, y = verb, group = id)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) Sometimes the “blob” gets too dense. This can be fixed by selecting a subset of persons to visualize. ggplot(subset(wisclong, id &lt; 30), aes(x = grade, y = verb, group = id)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) We can add some color to our plot using the color argument and treating id as a factor. ggplot(subset(wisclong, id &lt; 30), aes(x = grade, y = verb, group = id, color = factor(id))) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank(), legend.position = &quot;none&quot; ) We can also get a gradient of colors by treatingid as continuous. ggplot(subset(wisclong, id &lt; 30), aes(x = grade, y = verb, group = id, color = id)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank(), legend.position = &quot;none&quot; ) It is also sometimes useful to look at the collection of individual-level plots. ggplot(subset(wisclong, id &lt;= 20), aes(x = grade, y = verb)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + facet_wrap( ~ id) + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank(), legend.position = &quot;none&quot; ) Some other aesthetics to get to the formal APA style. #ggplot version .. see also http://ggplot.yhathq.com/docs/index.html ggplot(subset(wisclong, id &lt;= 20), aes(x = grade, y = verb, group = id)) + geom_point() + geom_line() + xlab(&quot;Grade&quot;) + ylab(&quot;WISC Verbal Score&quot;) + ylim(0,100) + scale_x_continuous(breaks=seq(1,6,by=1)) + ggtitle(&quot;Intraindividual Change in Verbal Ability&quot;) + theme_classic() + #increase font size of axis and point labels theme(axis.title = element_text(size = rel(1.5)), axis.text = element_text(size = rel(1.2)), legend.position = &quot;none&quot;) Saving the plot file. See also outputting plots to a file. ggsave(filename = &quot;wiscverbal.png&quot;, width = 5, height = 5, dpi=300) Now we have a good set of strategies to apply when looking at new longitudinal data. "],["3.5-references.html", "3.5 References", " 3.5 References "]]
