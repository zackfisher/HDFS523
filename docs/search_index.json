[["2-chapter-2.html", "Chapter 2 Data Cleaning", " Chapter 2 Data Cleaning In Chapter 2 we will work through some basic data cleaning operations useful in longitudinal data analysis. The basic idea is provide a set of scripts to use for exploring new repeated measures data sets. "],["2.1-example-data.html", "2.1 Example Data", " 2.1 Example Data For Chapter 2 we will make use of the longitudinal Wechsler Intelligence Scale for Children [WISC; Wechsler, -Wechsler (1949)] dataset described by Osborne and Suddick (1972). These data have been detailed extensively in a number of papers (McArdle and Epstein 1987; McArdle 1988; Mcardle and Aber 1990; McArdle and Nesselroade 1994) and are used here with with permission. The WISC data contains repeated measures data from 204 children between the ages of 6 and 11 years old (during grades 6, 7, 9 and 11). Thee repeated measures include component scores for the verbal tests and performance subtests at all four occasions, along with verbal subtest scores for the information, comprehension, similarities, and vocabulary domains at the first and last measurement occasion. The demographics variables mother’s education (continuous in years) and mother graduated high school (dichotomous) are also included. References "],["2.2-reading-in-repeated-measures-data.html", "2.2 Reading in Repeated Measures Data", " 2.2 Reading in Repeated Measures Data We can read in the WISC data directly from the QuantDev website. filepath &lt;- &quot;https://quantdev.ssri.psu.edu/sites/qdev/files/wisc3raw.csv&quot; wisc3raw &lt;- read.csv(file=url(filepath), header=TRUE) Additional details on importing different data types into R can be found here: http://www.statmethods.net/input/importingdata.html. "],["2.3-familiarize-yourself-with-the-data.html", "2.3 Familiarize Yourself with the Data", " 2.3 Familiarize Yourself with the Data Let’s take an initial look at the structure of our data object using str() str(wisc3raw) ## &#39;data.frame&#39;: 204 obs. of 20 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ verb1 : num 24.4 12.4 32.4 22.7 28.2 ... ## $ verb2 : num 27 14.4 33.5 28.4 37.8 ... ## $ verb4 : num 39.6 21.9 34.3 42.2 41.1 ... ## $ verb6 : num 55.6 37.8 50.2 44.7 71 ... ## $ perfo1 : num 19.8 5.9 27.6 33.2 27.6 ... ## $ perfo2 : num 23 13.4 45 29.7 44.4 ... ## $ perfo4 : num 43.9 18.3 47 46 65.5 ... ## $ perfo6 : num 44.2 40.4 77.7 61.7 64.2 ... ## $ info1 : num 31.3 13.8 35 24.8 25.3 ... ## $ comp1 : num 25.6 14.8 34.7 31.4 30.3 ... ## $ simu1 : num 22.93 7.58 28.05 8.21 15.98 ... ## $ voca1 : num 22.2 15.4 26.8 20.2 35.4 ... ## $ info6 : num 69.9 41.9 60.4 52.9 67.4 ... ## $ comp6 : num 44.4 44.9 50.3 42.7 86.7 ... ## $ simu6 : num 68 33.9 35.8 45.8 72.4 ... ## $ voca6 : num 51.2 37.7 55.5 36 60.4 ... ## $ momed : num 9.5 5.5 14 14 11.5 14 9.5 5.5 9.5 11.5 ... ## $ grad : int 0 0 1 1 0 1 0 0 0 0 ... ## $ constant: int 1 1 1 1 1 1 1 1 1 1 ... From the output, we can also see that the data frame consists of 204 observations (rows) and 20 variables (columns). Each variable’s name and data type is also listed. Methods like the ones above can be an effective way to initially familiarize yourself with the main features of a dataset. "],["2.4-look-for-duplicated-ids.html", "2.4 Look for Duplicated IDs", " 2.4 Look for Duplicated IDs It is always worth looking for non-unique ID numbers when ID labels are included in a dataset. Here we have an id variable indicating the subject number. Since our data is in a long format (more on that later) duplicate IDs may indicate a potential problem with the data source or clues on how the data is structured. any(duplicated(wisc3raw$id)) ## [1] FALSE "],["2.5-using-table-to-spot-irregularities.html", "2.5 Using table() to Spot Irregularities", " 2.5 Using table() to Spot Irregularities When a variable takes on a limited range of values it is often useful to screen for irregularities or invalid values. This is common across all variable types and can occur for character strings, numeric, integer and factor types. For example, we would expect the grad variable to only take the values of zero or one. We can use the table() function to quickly confirm this. By default table() simply omits any values coded as NA. To include a count of the NA values use the useNA argument of table() as follows: table(wisc3raw$grad, useNA = &quot;always&quot;) ## ## 0 1 &lt;NA&gt; ## 158 46 0 "],["2.6-missing-data.html", "2.6 Missing Data", " 2.6 Missing Data Dealing with missing data in a consistent manner is one of the most important aspects of data cleaning. When data are imported into R it is common to discover missing values are coded according to a variety of conventions. Often a first step in handling missing data involves recoding missing values as NA. Writing bespoke code to handle the different types of missing data one might encounter is tedious and unnecessary. naniar (Tierney et al. 2021) is a useful package with many convenience functions for managing missing data in R. Here we demonstrate some of this functionality. 2.6.1 Generating Example Data Since the WISC data does not contain missing values it is helpful to generate a synthetic dataset containing some commonly encountered missing data codes. set.seed(123) wisc_miss &lt;- wisc3raw wisc_miss$verb1[sample(nrow(wisc_miss),100)] &lt;- -99 wisc_miss$comp1[sample(nrow(wisc_miss),75)] &lt;- &quot;N/A&quot; wisc_miss$info1[sample(nrow(wisc_miss),50)] &lt;- &quot;NA&quot; 2.6.2 Recoding Values with NA Now that we have a dataset with missing values we can use naniar to recode these values to NA. na_strings &lt;- c(&quot;NA&quot;, &quot;N/A&quot;, -99) wisc_miss &lt;- naniar::replace_with_na_all( wisc_miss, condition = ~.x %in% na_strings ) See the naniar vignette on recoding NA values for more detailed information on the package functionality. 2.6.3 Missing Data Visualization Once we have recoded our data in a consistent manner we can use visualizations to explore the missing data. The vis_miss() function from naniar is a good starting point for visualizing the amount of missing data in our dataset. The plots shows the missing values in black and non-missing values in gray. In addition, percentages of missing data in both the dataset and individual variables are provided. naniar::vis_miss(wisc_miss) ## Warning: `gather_()` was deprecated in tidyr 1.2.0. ## ℹ Please use `gather()` instead. ## ℹ The deprecated feature was likely used in the visdat package. ## Please report the issue at &lt;]8;;https://github.com/ropensci/visdat/issueshttps://github.com/ropensci/visdat/issues]8;;&gt;. It is often useful to look at combinations of missingness among different variables. naniar::gg_miss_upset(wisc_miss) We can also look at the percentage of missing data across a factor variable. naniar::gg_miss_fct(x = wisc_miss, fct = grad) Many missing data visualizations are described in the naniar vignette on missing data visualization including plots for exploring missing data mechanisms. References "],["2.7-exporting-data.html", "2.7 Exporting Data", " 2.7 Exporting Data Depending on work-flow, you may need to export your dataset for use in another statistical software program. The write.csv() function is a convenient method for outputting comma delimited files. write.csv(wisc3raw, file = &quot;wisc3raw.csv&quot;, row.names = FALSE, na = &quot;-99&quot;) Note that by default the write.csv() function will include an extra column of row numbers and will notate missing data with an NA. More information on exporting data is available at http://www.statmethods.net/input/exportingdata.html. "],["2.8-reshaping-repeated-measures-data.html", "2.8 Reshaping Repeated Measures Data", " 2.8 Reshaping Repeated Measures Data Behavioral science tends to use relational data structures - in basic form, spreadsheets. Typically, the data are stored in a data frame (a “fancy” matrix) with multiple rows and columns. Two common schemata used to accommodate repeated measures data are wide format and long format. Different analysis and plotting functions require different kinds of data input. Thus, it is imperative that one can convert the data back and forth between wide and long formats. There are lots of ways to do this. We illustrate one way. Sidebar: The dput() function provides a convenient method to get the variable names (or any R object) into a format that can be read back into R. For example, this can be helpful when working with a long vector of strings. dput(colnames(wisc3raw)) ## c(&quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, ## &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;info1&quot;, &quot;comp1&quot;, &quot;simu1&quot;, &quot;voca1&quot;, &quot;info6&quot;, ## &quot;comp6&quot;, &quot;simu6&quot;, &quot;voca6&quot;, &quot;momed&quot;, &quot;grad&quot;, &quot;constant&quot;) First, let’s subset our data to only include the variables we need for this analysis. var_names_sub &lt;- c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;, &quot;grad&quot; ) wiscraw &lt;- wisc3raw[,var_names_sub] head(wiscraw) ## id verb1 verb2 verb4 verb6 perfo1 perfo2 perfo4 perfo6 momed grad ## 1 1 24.42 26.98 39.61 55.64 19.84 22.97 43.90 44.19 9.5 0 ## 2 2 12.44 14.38 21.92 37.81 5.90 13.44 18.29 40.38 5.5 0 ## 3 3 32.43 33.51 34.30 50.18 27.64 45.02 46.99 77.72 14.0 1 ## 4 4 22.69 28.39 42.16 44.72 33.16 29.68 45.97 61.66 14.0 1 ## 5 5 28.23 37.81 41.06 70.95 27.64 44.42 65.48 64.22 11.5 0 ## 6 6 16.06 20.12 38.02 39.94 8.45 15.78 26.99 39.08 14.0 1 2.8.1 Reshape Wide to Long One way to go from wide to long is using the reshape() function from base R. Notice, the varying argument contains the repeated measures columns we want to stack and the timevar is a new variable containing the grade level information previosuly appended at the end of the colnames listed in varying. # reshape data from wide to long wisclong &lt;- reshape( data = wiscraw, varying = c(&quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;,&quot;verb6&quot;, &quot;perfo1&quot;,&quot;perfo2&quot;,&quot;perfo4&quot;,&quot;perfo6&quot;), timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), direction = &quot;long&quot;, sep = &quot;&quot; ) # reorder by id and day wisclong &lt;- wisclong[ order(wisclong$id, wisclong$grade), ] head(wisclong, 8) ## id momed grad grade verb perfo ## 1.1 1 9.5 0 1 24.42 19.84 ## 1.2 1 9.5 0 2 26.98 22.97 ## 1.4 1 9.5 0 4 39.61 43.90 ## 1.6 1 9.5 0 6 55.64 44.19 ## 2.1 2 5.5 0 1 12.44 5.90 ## 2.2 2 5.5 0 2 14.38 13.44 ## 2.4 2 5.5 0 4 21.92 18.29 ## 2.6 2 5.5 0 6 37.81 40.38 Again, notice how reshape automatically split verb1, verb2, etc. into a string name and a grade variable. 2.8.2 Reshape Long to Wide Now we go from long to wide, again using the reshape() function. The v.names argument specifies the variables to be expanded column wise based on the repeated measure specified in timevar. #reshaping long to wide wiscwide &lt;- reshape( data = wisclong, timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), v.names = c(&quot;verb&quot;,&quot;perfo&quot;), direction = &quot;wide&quot;, sep = &quot;&quot; ) # reordering columns wiscwide &lt;- wiscwide[, c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;,&quot;grad&quot; )] head(wiscwide) ## id verb1 verb2 verb4 verb6 perfo1 perfo2 perfo4 perfo6 momed grad ## 1.1 1 24.42 26.98 39.61 55.64 19.84 22.97 43.90 44.19 9.5 0 ## 2.1 2 12.44 14.38 21.92 37.81 5.90 13.44 18.29 40.38 5.5 0 ## 3.1 3 32.43 33.51 34.30 50.18 27.64 45.02 46.99 77.72 14.0 1 ## 4.1 4 22.69 28.39 42.16 44.72 33.16 29.68 45.97 61.66 14.0 1 ## 5.1 5 28.23 37.81 41.06 70.95 27.64 44.42 65.48 64.22 11.5 0 ## 6.1 6 16.06 20.12 38.02 39.94 8.45 15.78 26.99 39.08 14.0 1 Using functions included in base R can be useful in a number of situations. One example is package development where one may wants to limit dependencies. That said, many people find reshape to be unnecessarily complicated. A similar, and potentially more convenient, set of functions have been developed for reshaping data in the tidyr (Wickham 2021) package. For those interested take a look at the pivot_longer() and pivot_wider() functions. For examples using tidyr to reshape data see the tidyr vignette on pivoting. References "]]
