[["index.html", "HDFS 523: Strategies for Data Analysis in Developmental Research Chapter 1 About This Book", " HDFS 523: Strategies for Data Analysis in Developmental Research Zachary F. Fisher 2025-01-30 Chapter 1 About This Book This book provides the course notes for HDFS 523. It is currently under development, so any feedback is appreciated (e.g., during class, via email, or the edit link in the header). This first chapter is just about how to use the book – the course content starts in Chapter 2. "],["1.1-why-this-book.html", "1.1 Why this book?", " 1.1 Why this book? There are a few goals of moving from “textbook + slides + exercises” to an ebook. For now, the main goal is to update and integrate code contents from the course into one consistent format, rather than having multiple files to sort through on Canvas. "],["1.2-code-folding.html", "1.2 Code Folding", " 1.2 Code Folding The book combines lecture slides and R coding examples. It is often convenient to hide code when introducing new material. This is accomplished using code folding. An example of code folding is given on this page. Below, a histogram integrated into the text. By clicking on the button called “Show Code” on the top of the page, the R code that produced the histogram will also be visible. Notice that you may need to scroll horizontally to see all of the text in the code window. Also notice that when you hover your mouse over the code window, an icon appears in the top right corner – this lets you copy the block of code with one click. # Here is some R code. You don&#39;t have to look at it when reading the book, but it is here when you need it x &lt;- rnorm(200) hist(x, col = &quot;#4B9CD3&quot;) "],["1.3-acknowledgements.html", "1.3 Acknowledgements", " 1.3 Acknowledgements Many people have contributed to the course materials for HDFS 523. Most importantly, many of the original R markdown files for the course were developed by Nilam Ram and Zita Oravecz. "],["2-chapter-2.html", "Chapter 2 Data Cleaning", " Chapter 2 Data Cleaning In Chapter 2 we will work through some basic data cleaning operations useful in longitudinal data analysis. The basic idea is provide a set of scripts to use for exploring new repeated measures data sets. "],["2.1-example-data.html", "2.1 Example Data", " 2.1 Example Data For Chapter 2 we will make use of the longitudinal Wechsler Intelligence Scale for Children [WISC; Wechsler, -Wechsler (1949)] dataset described by Osborne and Suddick (1972). These data have been detailed extensively in a number of papers (McArdle and Epstein 1987; McArdle 1988; Mcardle and Aber 1990; McArdle and Nesselroade 1994) and are used here with with permission. The WISC data contains repeated measures data from 204 children between the ages of 6 and 11 years old (during grades 6, 7, 9 and 11). Thee repeated measures include component scores for the verbal tests and performance subtests at all four occasions, along with verbal subtest scores for the information, comprehension, similarities, and vocabulary domains at the first and last measurement occasion. The demographics variables mother’s education (continuous in years) and mother graduated high school (dichotomous) are also included. References McArdle, J. J. 1988. “Dynamic but Structural Equation Modeling of Repeated Measures Data.” In Handbook of Multivariate Experimental Psychology, 2nd Ed, 561–614. Perspectives on Individual Differences. New York, NY, US: Plenum Press. https://doi.org/10.1007/978-1-4613-0893-5_17. Mcardle, J. J., and MARK S. Aber. 1990. “Chapter 5 - Patterns of Change Within Latent Variable Structural Equation Models.” In Statistical Methods in Longitudinal Research, edited by Alexander von Eye, 1:151–224. Statistical Modeling and Decision Science. San Diego: Academic Press. https://doi.org/10.1016/B978-0-12-724960-5.50010-X. McArdle, J. J., and David Epstein. 1987. “Latent Growth Curves Within Developmental Structural Equation Models.” Child Development 58 (1): 110–33. https://doi.org/10.2307/1130295. McArdle, J. J., and John R. Nesselroade. 1994. “Using Multivariate Data to Structure Developmental Change.” In Life-Span Developmental Psychology: Methodological Contributions, 223–67. The West Virginia University Conferences on Life-Span Developmental Psychology. Hillsdale, NJ, US: Lawrence Erlbaum Associates, Inc. Osborne, R. T., and D. E. Suddick. 1972. “A Longitudinal Investigation of the Intellectual Differentiation Hypothesis.” The Journal of Genetic Psychology: Research and Theory on Human Development 121 (1): 83–89. https://doi.org/10.1080/00221325.1972.10533131. Wechsler, David. 1949. Wechsler Intelligence Scale for Children. Wechsler Intelligence Scale for Children. San Antonio, TX, US: Psychological Corporation. "],["2.2-reading-in-repeated-measures-data.html", "2.2 Reading in Repeated Measures Data", " 2.2 Reading in Repeated Measures Data We can read in the WISC data directly from the QuantDev website. filepath &lt;- &quot;https://quantdev.ssri.psu.edu/sites/qdev/files/wisc3raw.csv&quot; wisc3raw &lt;- read.csv(file=url(filepath), header=TRUE) Additional details on importing different data types into R can be found here: http://www.statmethods.net/input/importingdata.html. "],["2.3-familiarize-yourself-with-the-data.html", "2.3 Familiarize Yourself with the Data", " 2.3 Familiarize Yourself with the Data Let’s take an initial look at the structure of our data object using str() str(wisc3raw) ## &#39;data.frame&#39;: 204 obs. of 20 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ verb1 : num 24.4 12.4 32.4 22.7 28.2 ... ## $ verb2 : num 27 14.4 33.5 28.4 37.8 ... ## $ verb4 : num 39.6 21.9 34.3 42.2 41.1 ... ## $ verb6 : num 55.6 37.8 50.2 44.7 71 ... ## $ perfo1 : num 19.8 5.9 27.6 33.2 27.6 ... ## $ perfo2 : num 23 13.4 45 29.7 44.4 ... ## $ perfo4 : num 43.9 18.3 47 46 65.5 ... ## $ perfo6 : num 44.2 40.4 77.7 61.7 64.2 ... ## $ info1 : num 31.3 13.8 35 24.8 25.3 ... ## $ comp1 : num 25.6 14.8 34.7 31.4 30.3 ... ## $ simu1 : num 22.93 7.58 28.05 8.21 15.98 ... ## $ voca1 : num 22.2 15.4 26.8 20.2 35.4 ... ## $ info6 : num 69.9 41.9 60.4 52.9 67.4 ... ## $ comp6 : num 44.4 44.9 50.3 42.7 86.7 ... ## $ simu6 : num 68 33.9 35.8 45.8 72.4 ... ## $ voca6 : num 51.2 37.7 55.5 36 60.4 ... ## $ momed : num 9.5 5.5 14 14 11.5 14 9.5 5.5 9.5 11.5 ... ## $ grad : int 0 0 1 1 0 1 0 0 0 0 ... ## $ constant: int 1 1 1 1 1 1 1 1 1 1 ... From the output, we can also see that the data frame consists of 204 observations (rows) and 20 variables (columns). Each variable’s name and data type is also listed. Methods like the ones above can be an effective way to initially familiarize yourself with the main features of a dataset. "],["2.4-look-for-duplicated-ids.html", "2.4 Look for Duplicated IDs", " 2.4 Look for Duplicated IDs It is always worth looking for non-unique ID numbers when ID labels are included in a dataset. Here we have an id variable indicating the subject number. Since our data is in a long format (more on that later) duplicate IDs may indicate a potential problem with the data source or clues on how the data is structured. any(duplicated(wisc3raw$id)) ## [1] FALSE "],["2.5-using-table-to-spot-irregularities.html", "2.5 Using table() to Spot Irregularities", " 2.5 Using table() to Spot Irregularities When a variable takes on a limited range of values it is often useful to screen for irregularities or invalid values. This is common across all variable types and can occur for character strings, numeric, integer and factor types. For example, we would expect the grad variable to only take the values of zero or one. We can use the table() function to quickly confirm this. By default table() simply omits any values coded as NA. To include a count of the NA values use the useNA argument of table() as follows: table(wisc3raw$grad, useNA = &quot;always&quot;) ## ## 0 1 &lt;NA&gt; ## 158 46 0 "],["2.6-missing-data.html", "2.6 Missing Data", " 2.6 Missing Data Dealing with missing data in a consistent manner is one of the most important aspects of data cleaning. When data are imported into R it is common to discover missing values are coded according to a variety of conventions. Often a first step in handling missing data involves recoding missing values as NA. Writing bespoke code to handle the different types of missing data one might encounter is tedious and unnecessary. naniar (Tierney et al. 2021) is a useful package with many convenience functions for managing missing data in R. Here we demonstrate some of this functionality. 2.6.1 Generating Example Data Since the WISC data does not contain missing values it is helpful to generate a synthetic dataset containing some commonly encountered missing data codes. set.seed(123) wisc_miss &lt;- wisc3raw wisc_miss$verb1[sample(nrow(wisc_miss),100)] &lt;- -99 wisc_miss$comp1[sample(nrow(wisc_miss),75)] &lt;- &quot;N/A&quot; wisc_miss$info1[sample(nrow(wisc_miss),50)] &lt;- &quot;NA&quot; 2.6.2 Recoding Values with NA Now that we have a dataset with missing values we can use naniar to recode these values to NA. na_strings &lt;- c(&quot;NA&quot;, &quot;N/A&quot;, -99) wisc_miss &lt;- naniar::replace_with_na_all( wisc_miss, condition = ~.x %in% na_strings ) See the naniar vignette on recoding NA values for more detailed information on the package functionality. 2.6.3 Missing Data Visualization Once we have recoded our data in a consistent manner we can use visualizations to explore the missing data. The vis_miss() function from naniar is a good starting point for visualizing the amount of missing data in our dataset. The plots shows the missing values in black and non-missing values in gray. In addition, percentages of missing data in both the dataset and individual variables are provided. naniar::vis_miss(wisc_miss) It is often useful to look at combinations of missingness among different variables. naniar::gg_miss_upset(wisc_miss) We can also look at the percentage of missing data across a factor variable. naniar::gg_miss_fct(x = wisc_miss, fct = grad) Many missing data visualizations are described in the naniar vignette on missing data visualization including plots for exploring missing data mechanisms. References Tierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. Naniar: Data Structures, Summaries, and Visualisations for Missing Data. https://CRAN.R-project.org/package=naniar. "],["2.7-exporting-data.html", "2.7 Exporting Data", " 2.7 Exporting Data Depending on work-flow, you may need to export your dataset for use in another statistical software program. The write.csv() function is a convenient method for outputting comma delimited files. write.csv(wisc3raw, file = &quot;wisc3raw.csv&quot;, row.names = FALSE, na = &quot;-99&quot;) Note that by default the write.csv() function will include an extra column of row numbers and will notate missing data with an NA. More information on exporting data is available at http://www.statmethods.net/input/exportingdata.html. "],["2.8-reshaping-repeated-measures-data.html", "2.8 Reshaping Repeated Measures Data", " 2.8 Reshaping Repeated Measures Data Behavioral science tends to use relational data structures - in basic form, spreadsheets. Typically, the data are stored in a data frame (a “fancy” matrix) with multiple rows and columns. Two common schemata used to accommodate repeated measures data are wide format and long format. Different analysis and plotting functions require different kinds of data input. Thus, it is imperative that one can convert the data back and forth between wide and long formats. There are lots of ways to do this. We illustrate one way. Sidebar: The dput() function provides a convenient method to get the variable names (or any R object) into a format that can be read back into R. For example, this can be helpful when working with a long vector of strings. dput(colnames(wisc3raw)) ## c(&quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, ## &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;info1&quot;, &quot;comp1&quot;, &quot;simu1&quot;, &quot;voca1&quot;, &quot;info6&quot;, ## &quot;comp6&quot;, &quot;simu6&quot;, &quot;voca6&quot;, &quot;momed&quot;, &quot;grad&quot;, &quot;constant&quot;) First, let’s subset our data to only include the variables we need for this analysis. var_names_sub &lt;- c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;, &quot;grad&quot; ) wiscraw &lt;- wisc3raw[,var_names_sub] head(wiscraw) ## id verb1 verb2 verb4 verb6 perfo1 perfo2 perfo4 perfo6 momed grad ## 1 1 24.42 26.98 39.61 55.64 19.84 22.97 43.90 44.19 9.5 0 ## 2 2 12.44 14.38 21.92 37.81 5.90 13.44 18.29 40.38 5.5 0 ## 3 3 32.43 33.51 34.30 50.18 27.64 45.02 46.99 77.72 14.0 1 ## 4 4 22.69 28.39 42.16 44.72 33.16 29.68 45.97 61.66 14.0 1 ## 5 5 28.23 37.81 41.06 70.95 27.64 44.42 65.48 64.22 11.5 0 ## 6 6 16.06 20.12 38.02 39.94 8.45 15.78 26.99 39.08 14.0 1 2.8.1 Reshape Wide to Long One way to go from wide to long is using the reshape() function from base R. Notice, the varying argument contains the repeated measures columns we want to stack and the timevar is a new variable containing the grade level information previosuly appended at the end of the colnames listed in varying. # reshape data from wide to long wisclong &lt;- reshape( data = wiscraw, varying = c(&quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;,&quot;verb6&quot;, &quot;perfo1&quot;,&quot;perfo2&quot;,&quot;perfo4&quot;,&quot;perfo6&quot;), timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), direction = &quot;long&quot;, sep = &quot;&quot; ) # reorder by id and day wisclong &lt;- wisclong[ order(wisclong$id, wisclong$grade), ] head(wisclong, 8) ## id momed grad grade verb perfo ## 1.1 1 9.5 0 1 24.42 19.84 ## 1.2 1 9.5 0 2 26.98 22.97 ## 1.4 1 9.5 0 4 39.61 43.90 ## 1.6 1 9.5 0 6 55.64 44.19 ## 2.1 2 5.5 0 1 12.44 5.90 ## 2.2 2 5.5 0 2 14.38 13.44 ## 2.4 2 5.5 0 4 21.92 18.29 ## 2.6 2 5.5 0 6 37.81 40.38 Again, notice how reshape automatically split verb1, verb2, etc. into a string name and a grade variable. 2.8.2 Reshape Long to Wide Now we go from long to wide, again using the reshape() function. The v.names argument specifies the variables to be expanded column wise based on the repeated measure specified in timevar. #reshaping long to wide wiscwide &lt;- reshape( data = wisclong, timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), v.names = c(&quot;verb&quot;,&quot;perfo&quot;), direction = &quot;wide&quot;, sep = &quot;&quot; ) # reordering columns wiscwide &lt;- wiscwide[, c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;,&quot;grad&quot; )] head(wiscwide) ## id verb1 verb2 verb4 verb6 perfo1 perfo2 perfo4 perfo6 momed grad ## 1.1 1 24.42 26.98 39.61 55.64 19.84 22.97 43.90 44.19 9.5 0 ## 2.1 2 12.44 14.38 21.92 37.81 5.90 13.44 18.29 40.38 5.5 0 ## 3.1 3 32.43 33.51 34.30 50.18 27.64 45.02 46.99 77.72 14.0 1 ## 4.1 4 22.69 28.39 42.16 44.72 33.16 29.68 45.97 61.66 14.0 1 ## 5.1 5 28.23 37.81 41.06 70.95 27.64 44.42 65.48 64.22 11.5 0 ## 6.1 6 16.06 20.12 38.02 39.94 8.45 15.78 26.99 39.08 14.0 1 Using functions included in base R can be useful in a number of situations. One example is package development where one may wants to limit dependencies. That said, many people find reshape to be unnecessarily complicated. A similar, and potentially more convenient, set of functions have been developed for reshaping data in the tidyr (Wickham 2021) package. For those interested take a look at the pivot_longer() and pivot_wider() functions. For examples using tidyr to reshape data see the tidyr vignette on pivoting. References ———. 2021. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr. "],["3-chapter-3.html", "Chapter 3 Describing Longitudinal Data", " Chapter 3 Describing Longitudinal Data In Chapter 3 we will look at some option for describing and visualizing longitudinal data. "],["3.1-example-data-1.html", "3.1 Example Data", " 3.1 Example Data Again we will make use of the WISC data described in Chapter 2. The following commands recreate the wide and long data we will use throughout this chapter. filepath &lt;- &quot;https://quantdev.ssri.psu.edu/sites/qdev/files/wisc3raw.csv&quot; wisc3raw &lt;- read.csv(file=url(filepath),header=TRUE) var_names_sub &lt;- c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;, &quot;grad&quot; ) wiscraw &lt;- wisc3raw[,var_names_sub] # reshaping wide to long wisclong &lt;- reshape( data = wiscraw, varying = c(&quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;,&quot;verb6&quot;, &quot;perfo1&quot;,&quot;perfo2&quot;,&quot;perfo4&quot;,&quot;perfo6&quot;), timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), direction = &quot;long&quot;, sep = &quot;&quot; ) # reorder by id and day wisclong &lt;- wisclong[ order(wisclong$id, wisclong$grade), ] #reshaping long to wide wiscwide &lt;- reshape( data = wisclong, timevar = c(&quot;grade&quot;), idvar = c(&quot;id&quot;), v.names = c(&quot;verb&quot;,&quot;perfo&quot;), direction = &quot;wide&quot;, sep = &quot;&quot; ) # reordering columns wiscwide &lt;- wiscwide[, c( &quot;id&quot;, &quot;verb1&quot;, &quot;verb2&quot;, &quot;verb4&quot;, &quot;verb6&quot;, &quot;perfo1&quot;, &quot;perfo2&quot;, &quot;perfo4&quot;, &quot;perfo6&quot;, &quot;momed&quot;,&quot;grad&quot; )] "],["3.2-describing-means-and-variances.html", "3.2 Describing Means and Variances", " 3.2 Describing Means and Variances Once the wide and long data sets are in place, we can begin describing and plotting the data. Descriptive statistics and visualization are one of the most important aspects of data analysis. Descriptives and plots will be produced from wide data and long data to show the information that can be gleaned from each construction. Having both in place facilitates learning about the data. Continually keep in mind what portions of the data-box are being described (e.g., persons, variables, occasions). We can do a quick look at descriptives using the describe() function from the psych (Revelle 2021) package. Note the n in both outputs. psych::describe(wiscwide) ## vars n mean sd median trimmed mad min max range skew ## id 1 204 102.50 59.03 102.50 102.50 75.61 1.00 204.00 203.00 0.00 ## verb1 2 204 19.59 5.81 19.34 19.50 5.41 3.33 35.15 31.82 0.13 ## verb2 3 204 25.42 6.11 25.98 25.40 6.57 5.95 39.85 33.90 -0.06 ## verb4 4 204 32.61 7.32 32.82 32.42 7.18 12.60 52.84 40.24 0.23 ## verb6 5 204 43.75 10.67 42.55 43.46 11.30 17.35 72.59 55.24 0.24 ## perfo1 6 204 17.98 8.35 17.66 17.69 8.30 0.00 46.58 46.58 0.35 ## perfo2 7 204 27.69 9.99 26.57 27.34 10.51 7.83 59.58 51.75 0.39 ## perfo4 8 204 39.36 10.27 39.09 39.28 10.04 7.81 75.61 67.80 0.15 ## perfo6 9 204 50.93 12.48 51.76 51.07 13.27 10.26 89.01 78.75 -0.06 ## momed 10 204 10.81 2.70 11.50 11.00 2.97 5.50 18.00 12.50 -0.36 ## grad 11 204 0.23 0.42 0.00 0.16 0.00 0.00 1.00 1.00 1.30 ## kurtosis se ## id -1.22 4.13 ## verb1 -0.05 0.41 ## verb2 -0.34 0.43 ## verb4 -0.08 0.51 ## verb6 -0.36 0.75 ## perfo1 -0.11 0.58 ## perfo2 -0.21 0.70 ## perfo4 0.59 0.72 ## perfo6 0.18 0.87 ## momed 0.01 0.19 ## grad -0.30 0.03 psych::describe(wisclong) ## vars n mean sd median trimmed mad min max range skew ## id 1 816 102.50 58.93 102.50 102.50 75.61 1.00 204.00 203.00 0.00 ## momed 2 816 10.81 2.69 11.50 11.00 2.97 5.50 18.00 12.50 -0.36 ## grad 3 816 0.23 0.42 0.00 0.16 0.00 0.00 1.00 1.00 1.31 ## grade 4 816 3.25 1.92 3.00 3.19 2.22 1.00 6.00 5.00 0.28 ## verb 5 816 30.34 11.86 28.46 29.39 11.33 3.33 72.59 69.26 0.71 ## perfo 6 816 33.99 16.14 33.14 33.34 18.14 0.00 89.01 89.01 0.34 ## kurtosis se ## id -1.20 2.06 ## momed 0.03 0.09 ## grad -0.28 0.01 ## grade -1.43 0.07 ## verb 0.33 0.42 ## perfo -0.43 0.56 3.2.1 Verbal Ability (All Persons and Occasions) Let’s focus on the repeated measures of verbal ability. This step is useful to get a general view of what verbal ability scores look like across persons and occasions, but note that we are ignoring Time. In doing so we are not considering how the repeated measures are nested within individuals. psych::describe(wisclong$verb) ## vars n mean sd median trimmed mad min max range skew kurtosis ## X1 1 816 30.34 11.86 28.46 29.39 11.33 3.33 72.59 69.26 0.71 0.33 ## se ## X1 0.42 In addition to the descriptive statistics we can look at a boxplot of verbal ability scores across persons and occasions. Here we will start to use the ggplot2 (Wickham 2016) package. library(&quot;ggplot2&quot;) ggplot(data = wisclong, aes(x=verb, y=..density..)) + geom_histogram(binwidth=2.5, fill = &quot;white&quot;, color = &quot;black&quot;) + geom_density(color = &quot;red&quot;) + ggtitle(&quot;Verbal Ability Score (across persons and occasions)&quot;) + xlab(&quot;Verbal Ability (Grade 1 to 6)&quot;) + ylab(&quot;Density&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) ## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(density)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 3.2.2 Verbal Ability (Across Time) Note that our variable is actually “multivariate” because we have repeated measures. We should really consider the time-dependence when we are looking at descriptive statistics and plots. Let’s now look at verbal ability scores across time collapsed across individuals. This can be done using either the describe() function and the wide data or the describeBy() function and the long data. Let’s look at descriptives using the wide data. psych::describe(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)]) ## vars n mean sd median trimmed mad min max range skew ## verb1 1 204 19.59 5.81 19.34 19.50 5.41 3.33 35.15 31.82 0.13 ## verb2 2 204 25.42 6.11 25.98 25.40 6.57 5.95 39.85 33.90 -0.06 ## verb4 3 204 32.61 7.32 32.82 32.42 7.18 12.60 52.84 40.24 0.23 ## verb6 4 204 43.75 10.67 42.55 43.46 11.30 17.35 72.59 55.24 0.24 ## kurtosis se ## verb1 -0.05 0.41 ## verb2 -0.34 0.43 ## verb4 -0.08 0.51 ## verb6 -0.36 0.75 Identical results can be obtained using the long data. psych::describeBy(wisclong[,c(&quot;verb&quot;)], group = wisclong$grade) ## ## Descriptive statistics by group ## group: 1 ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 204 19.59 5.81 19.34 19.5 5.41 3.33 35.15 31.82 0.13 -0.05 0.41 ## ------------------------------------------------------------ ## group: 2 ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 204 25.42 6.11 25.98 25.4 6.57 5.95 39.85 33.9 -0.06 -0.34 0.43 ## ------------------------------------------------------------ ## group: 4 ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 204 32.61 7.32 32.82 32.42 7.18 12.6 52.84 40.24 0.23 -0.08 0.51 ## ------------------------------------------------------------ ## group: 6 ## vars n mean sd median trimmed mad min max range skew kurtosis ## X1 1 204 43.75 10.67 42.55 43.46 11.3 17.35 72.59 55.24 0.24 -0.36 ## se ## X1 0.75 We can visualize the distribution of verbal scores across grades in a number of different ways. Here we have a histogram. ggplot(data=wisclong, aes(x=verb)) + geom_histogram(binwidth=5, pad = TRUE, fill=&quot;white&quot;, color=&quot;black&quot;) + facet_grid(grade ~ .) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Verbal Ability Score&quot;) + ylab(&quot;Density&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) ## Warning: Duplicated aesthetics after name standardisation: pad We can also create notched boxplots of the within-grade distributions (across individuals). From Wikipedia: Notched box plots apply a notch or narrowing of the box around the median. Notches are useful in offering a rough guide of the significance of the difference of medians; if the notches of two boxes do not overlap, this can provide evidence of a statistically significant difference between the medians. Adding the mean value to the plot gives us additonal information about central tendency and skew of the distribution. #boxplot by grade ggplot(data=wisclong, aes(x=factor(grade), y=verb)) + geom_boxplot(notch = TRUE) + stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, shape=23, size=3, fill=&quot;white&quot;) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + ylab(&quot;Verbal Ability Score&quot;) + xlab(&quot;Grade&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) Finally, we can view overlapping densities of the within-grade distributions of verbal ability scores. ggplot(data=wisclong, aes(x=verb)) + geom_density(aes(group=factor(grade), colour=factor(grade), fill=factor(grade)), alpha=0.3) + guides(colour=&quot;none&quot;, fill=guide_legend(title=&quot;Grade&quot;)) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + ylab(&quot;Density&quot;) + xlab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) Notice in these plots how much “change” there is at the sample level across grades. Is that expected? References Revelle, William. 2021. Psych: Procedures for Psychological, Psychometric, and Personality Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psych. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. "],["3.3-describing-covariances.html", "3.3 Describing Covariances", " 3.3 Describing Covariances In the previous section we looked at the means and variances. Because these are repeated measures, we can also look at covariances and correlations over time. A simple covariance and correlation matrix of the verbal scores across grades can be produced using the cov() and cor() function. cov(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)], use=&quot;complete.obs&quot;) ## verb1 verb2 verb4 verb6 ## verb1 33.72932 25.46388 30.88886 40.51478 ## verb2 25.46388 37.28784 33.81957 47.40488 ## verb4 30.88886 33.81957 53.58070 62.25489 ## verb6 40.51478 47.40488 62.25489 113.74332 cor(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)], use=&quot;complete.obs&quot;) ## verb1 verb2 verb4 verb6 ## verb1 1.0000000 0.7180209 0.7265974 0.6541040 ## verb2 0.7180209 1.0000000 0.7566242 0.7279080 ## verb4 0.7265974 0.7566242 1.0000000 0.7974552 ## verb6 0.6541040 0.7279080 0.7974552 1.0000000 A plot corresponding to the correlation matrix can be obtained in a number of different ways. First, using the pairs() function from base R. pairs(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)]) There is also a pairs.panel() function in the psych package. Here we see a LOESS smoothed fit line in red. psych::pairs.panels(wiscwide[,c(&quot;verb1&quot;,&quot;verb2&quot;,&quot;verb4&quot;,&quot;verb6&quot;)]) Finally, thescatterplotMatrix() from the car (Fox and Weisberg 2019) package can be used to create scatterplot matrices with confidence bands around the line of best fit. car::scatterplotMatrix(~ verb1 + verb2 + verb4 + verb6, data=wiscwide) Each of these functions can be customized with additional features. Those interested in specifics should consult the help documentation for each function (e.g. ?car::scatterplotMatrix). It is also worth noting the default behavior of these functions is to provide automatic, data-based ranges for each pair of variables separately. References Fox, John, and Sanford Weisberg. 2019. An R Companion to Applied Regression. Third. Thousand Oaks CA: Sage. https://socialsciences.mcmaster.ca/jfox/Books/Companion/. "],["3.4-individual-level-descriptives.html", "3.4 Individual-Level Descriptives", " 3.4 Individual-Level Descriptives Note that our interest is often in individual development, rather than sample development. We need to consider how each individual is changing over time. Thus, we are interested in verbal ability across Time for each individual person. Visualization is typically our best tool for synthesizing the large amounts of information in individual-level data. ggplot(data = wisclong, aes(x = grade, y = verb, group = id)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) Sometimes the “blob” gets too dense. This can be fixed by selecting a subset of persons to visualize. ggplot(subset(wisclong, id &lt; 30), aes(x = grade, y = verb, group = id)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank() ) We can add some color to our plot using the color argument and treating id as a factor. ggplot(subset(wisclong, id &lt; 30), aes(x = grade, y = verb, group = id, color = factor(id))) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank(), legend.position = &quot;none&quot; ) We can also get a gradient of colors by treatingid as continuous. ggplot(subset(wisclong, id &lt; 30), aes(x = grade, y = verb, group = id, color = id)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank(), legend.position = &quot;none&quot; ) It is also sometimes useful to look at the collection of individual-level plots. ggplot(subset(wisclong, id &lt;= 20), aes(x = grade, y = verb)) + geom_point() + geom_line() + scale_x_continuous(breaks=seq(1,6,by=1)) + ylim(0,80) + ggtitle(&quot;Verbal Ability Score (across grades 1, 2, 4, 6)&quot;) + xlab(&quot;Grade&quot;) + ylab(&quot;Verbal Ability Score&quot;) + theme_bw() + facet_wrap( ~ id) + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(), strip.background = element_blank(), legend.position = &quot;none&quot; ) Some other aesthetics to get to the formal APA style. #ggplot version .. see also http://ggplot.yhathq.com/docs/index.html ggplot(subset(wisclong, id &lt;= 20), aes(x = grade, y = verb, group = id)) + geom_point() + geom_line() + xlab(&quot;Grade&quot;) + ylab(&quot;WISC Verbal Score&quot;) + ylim(0,100) + scale_x_continuous(breaks=seq(1,6,by=1)) + ggtitle(&quot;Intraindividual Change in Verbal Ability&quot;) + theme_classic() + #increase font size of axis and point labels theme(axis.title = element_text(size = rel(1.5)), axis.text = element_text(size = rel(1.2)), legend.position = &quot;none&quot;) Saving the plot file. See also outputting plots to a file. ggsave(filename = &quot;wiscverbal.png&quot;, width = 5, height = 5, dpi=300) Now we have a good set of strategies to apply when looking at new longitudinal data. "],["3.5-references.html", "3.5 References", " 3.5 References "],["4-chapter-4.html", "Chapter 4 Matrix Algebra", " Chapter 4 Matrix Algebra In Chapter 4 we will briefly review some basic algebra results useful for this course. Those needing a reliable reference for basic results in matrix algebra should consult the The Matrix Cookbook at https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf. "],["4.1-types-of-matrices.html", "4.1 Types of matrices", " 4.1 Types of matrices Remember that matrices are defined by rows (the first dimension) and columns (the second dimension): \\[ \\underset{m \\times n}{\\mathbf{A}} = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\\\ a_{41} &amp; a_{42} &amp; a_{43} \\end{bmatrix} \\] You can refer to a specific element in matrix using a subscript of the row and column index (e.g. \\(a_{31}\\)). For our purposes there are a few special matrices worth mentioning, 4.1.1 Square A square matrix has the same number of rows and columns. Covariance and correlation matrices are square. \\[ \\underset{n \\times n}{\\mathbf{A}} = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} \\\\ a_{21} &amp; a_{22} &amp; a_{23} &amp; a_{24} \\\\ a_{31} &amp; a_{32} &amp; a_{33} &amp; a_{34} \\\\ a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} \\end{bmatrix} \\] 4.1.2 Symmetric A symmetric matrix is a square matrix that equals its transpose. This means that corresponding entries on either side of the main diagonal are equal. \\[ \\begin{align} \\underset{n \\times n}{\\mathbf{A}} &amp;= \\begin{bmatrix} a &amp; ab &amp; ac &amp; ad \\\\ ab &amp; b &amp; bc &amp; bd \\\\ ac &amp; bc &amp; c &amp; cd \\\\ ad &amp; bd &amp; cd &amp; d \\end{bmatrix} \\\\ \\cr \\mathbf{A} &amp;= \\mathbf{A}&#39; \\end{align} \\] Matrix Transpose The transpose of a matrix is an operator which flips a matrix over its diagonal. That is, it switches the row and column indices of the matrix \\(A\\) by producing another matrix, often denoted by \\(A&#39;\\) (or \\(A^{T}\\)). Graphical Depiction of a Matrix Transpose https://leetcode.com/problems/transpose-matrix/ 4.1.3 Diagonal A diagonal matrix is a special case of a square symmetric matrix in which there are values along the diagonal, but zeros elsewhere: \\[ \\begin{align} \\underset{n \\times n}{\\mathbf{A}} &amp;= \\begin{bmatrix} a &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; b &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; c &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; d \\end{bmatrix} \\\\ \\cr \\mathbf{A} &amp;= \\mathbf{A}&#39; \\end{align} \\] 4.1.4 Identity An identity matrix is a special case of a diagonal matrix in which the elements of the diagonal are all 1: \\[ \\underset{n \\times n}{\\mathbf{I}} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] Any matrix multiplied by an identity matrix is unchanged. "],["4.2-operations-on-matrices.html", "4.2 Operations on Matrices", " 4.2 Operations on Matrices 4.2.1 Matrix Transpose As stated earlier the transpose of a matrix is an operator which flips a matrix over its diagonal. That is, it switches the row and column indices of the matrix \\(A\\) by producing another matrix, often denoted by \\(A&#39;\\) (or \\(A^{T}\\)). Some useful properties of the matrix transpose include: \\[ (\\mathbf{A + B})&#39; = \\mathbf{A&#39; + B&#39;}\\\\ (c\\mathbf{A&#39;}) = c(\\mathbf{A&#39;}) = (\\mathbf{A&#39;})c \\\\ (\\mathbf{A&#39;B}) = \\mathbf{B&#39;A}\\\\ (\\mathbf{AB})&#39; = \\mathbf{B&#39;A&#39;}\\\\ (\\mathbf{A&#39;})&#39; = \\mathbf{A} \\] Graphical Depiction of a Matrix Transpose https://leetcode.com/problems/transpose-matrix/ 4.2.2 Matrix Trace The trace of a square matrix is the sum of elements along the diagonal. The trace is only defined for a square matrix. For an \\(n \\times n\\) matrix the trace is defined as follows: \\[ tr(\\mathbf{A}) = \\sum_{i=1}^{n}{a_{ii}} = a_{11} + a_{22} + ... + a_{nn} \\] Graphical Depiction of a Matrix Trace Some useful properties of the matrix trace include: \\[ tr(\\mathbf{A + B}) = tr(\\mathbf{A}) + tr(\\mathbf{B})\\\\ tr(c\\mathbf{A}) = c(tr(\\mathbf{A})) \\\\ tr(\\mathbf{A}) = tr(\\mathbf{A&#39;})\\\\ tr(\\mathbf{AB}) = tr(\\mathbf{BA})\\\\ tr(\\mathbf{ABC}) = tr(\\mathbf{CAB})=tr(\\mathbf{BCA}) \\] 4.2.3 Addition For addition, matrices must be of the same order. Addition of two matrices is accomplished by adding corresponding elements, \\(c_{ij}=a_{ij}+b_{ij}\\) \\[ \\mathbf{A} = \\begin{bmatrix} 10 &amp; 5 \\\\ 9 &amp; 1 \\end{bmatrix} , \\enspace \\mathbf{B} = \\begin{bmatrix} 2 &amp; 1 \\\\ 20 &amp; 0 \\end{bmatrix}, \\enspace \\textrm{then } \\mathbf{A}+\\mathbf{B}= \\begin{bmatrix} 12 &amp; 6 \\\\ 29 &amp; 1 \\end{bmatrix} \\] Matrix addition is commutative (gives the same result whatever the order of the quantities involved), \\[ \\mathbf{A + B} = \\mathbf{B + A} \\] and associative (gives the same result whatever grouping their is, as long as order remains the same), \\[ \\mathbf{A + (B + C)} = \\mathbf{(A + B) + C} \\] and \\[ \\mathbf{A + (-B)} = \\mathbf{(A - B)}. \\] 4.2.4 Subtraction Like addition, subtraction requires matrices of the same order. Elements in the difference matrix are given by the algebraic difference between corresponding elements in matrices being subtracted: \\[ \\mathbf{A} = \\begin{bmatrix} 10 &amp; 5 \\\\ 9 &amp; 1 \\end{bmatrix} , \\enspace \\mathbf{B} = \\begin{bmatrix} 2 &amp; 1 \\\\ 20 &amp; 0 \\end{bmatrix}, \\enspace \\textrm{then } \\mathbf{A}-\\mathbf{B}= \\begin{bmatrix} 8 &amp; 4 \\\\ -11 &amp; 1 \\end{bmatrix} \\] 4.2.5 Matrix Multiplication Three useful rules to keep in mind regarding matrix multiplication: Only matrices of the form \\((m \\times n) * (n \\times p)\\) are conformable for multiplication. The number of columns in the premultiplier must equal the number of rows in the post multiplier. The product matrix will have the following order: \\(\\mathbf{A}_{m\\times n} \\mathbf{B}_{n\\times p} = \\mathbf{C}_{m \\times p}\\). Graphical Depiction of Rules 1 and 2 The element \\(c_{ij}\\) in the product matrix is the result of multiplying row \\(i\\) of the premultiplier matrix, and row \\(j\\) of the post multiplier matrix (e.g. (\\(c_{ij}=a_{i1}b_{1j} + a_{i2}b_{2j} + a_{i3}b_{3j}\\))). Graphical Depiction of Rule 3 https://code.kx.com/q/ref/mmu/ Matrix multiplication is associative (i.e. rearranging the parentheses in an expression will not change the result). That is, \\[ \\mathbf{(AB)C} = \\mathbf{A(BC)} \\] and is distributive with respect to addition, \\[ \\mathbf{A(B+C)} = \\mathbf{AB + AC} \\\\ \\mathbf{(B+C)A} = \\mathbf{BA + CA} \\\\ \\] If \\(c\\) is a scalar, then \\[ c(\\mathbf{AB})=c(\\mathbf{A})\\mathbf{B}=\\mathbf{A}(c\\mathbf{B})=(\\mathbf{AB})c \\] or equivalently, \\[ \\mathbf{A} = \\begin{bmatrix} 10 &amp; 5 \\\\ 9 &amp; 1 \\end{bmatrix}, \\enspace k=2, \\enspace k\\mathbf{A} = \\begin{bmatrix} 20 &amp; 10 \\\\ 18 &amp; 2 \\end{bmatrix}. \\] In general, matrices that can be multiplied are called ‘compatible’ or ‘comformable.’ Matrices in which the inner dimensions (i.e., columns of \\(\\mathbf{A}\\), rows of \\(\\mathbf{B}\\)) do not match are called ‘incompatible’ or ‘non-conformable.’ These cannot be multiplied. 4.2.6 Matrix Division Division is not defined for matrix operations, but may be accomplished by multiplication by the inverse matrix. In algebra, the reciprocal of a scalar is, by definition, the scalar raised to the minus one power (e.g. \\(5^{-1} = 1/5\\)), and equations may be solved by multiplication by reciprocals. For example: \\[ 5^{-1} = 1/5\\\\ 5x=35\\\\ 5^{-1}(5x)=5^{-1}(35)\\\\ x = 7 \\] Now consider the following equation where the vector \\(\\mathbf{x}\\) is unknown, \\[ \\mathbf{A}_{p \\times p} \\mathbf{x}_{p \\times 1} = \\mathbf{b}_{p \\times 1} \\] Each element in the column vector \\(\\mathbf{x}\\) is unknown and the solution involves solving a set of simultaneous equations for the unknown element of \\(\\mathbf{x}\\), \\[ a_{11}x_{1} + a_{12}x_{2} + \\dots + a_{1p}x_{p} = b1 \\\\ a_{21}x_{1} + a_{22}x_{2} + \\dots + a_{2p}x_{p} = b2 \\\\ \\vdots \\\\ a_{p1}x_{1} + a_{p2}x_{2} + \\dots + a_{pp}x_{p} = bp \\] A solution analogous to the scalar equations above would give the following solution for the elements of the vector \\(\\mathbf{x}\\): \\[ \\mathbf{A}_{p \\times p} \\mathbf{x}_{p \\times 1} = \\mathbf{b}_{p \\times 1} \\\\ \\mathbf{A}^{-1}_{p \\times p}\\mathbf{A}_{p \\times p} \\mathbf{x}_{p \\times 1} = \\mathbf{A}^{-1}_{p \\times p}\\mathbf{b}_{p \\times 1} \\\\ \\mathbf{I}_{p \\times p}\\mathbf{x}_{p \\times 1} = \\mathbf{A}^{-1}_{p \\times p}\\mathbf{b}_{p \\times 1} \\\\ \\mathbf{x}_{p \\times 1} = \\mathbf{A}^{-1}_{p \\times p}\\mathbf{b}_{p \\times 1} \\] The inverse of a matrix must satisfy the following properties: \\[ \\mathbf{AA^{-1}} = \\mathbf{A^{-1}A} = \\mathbf{I} \\] where \\(I\\) is the identity matrix with 1’s along the diagonal and 0’s elsewhere. So, why is division undefined for matrices. Here is a quick example. Suppose, \\(\\mathbf{A}\\) is a matrix and \\(\\mathbf{B}\\) is the inverse of \\(\\mathbf{A}\\), such that \\[ \\mathbf{AB} = \\mathbf{BA} = \\mathbf{I} \\] Now, let \\[ \\mathbf{A} = \\begin{bmatrix} 1 &amp; 2 \\\\ 1 &amp; 2 \\end{bmatrix} , \\enspace \\mathbf{B} = \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix}, \\] Then, \\[ \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix} \\begin{bmatrix} 1 &amp; 2 \\\\ 1 &amp; 2 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0\\\\ 0 &amp; 1 \\end{bmatrix}. \\] This means that \\(a+b=1\\) and \\(2a+2b = 0\\), which is a contradiction, suggesting A does not have an inverse. "],["4.3-references-1.html", "4.3 References", " 4.3 References Fox, John, and Sanford Weisberg. 2019. An R Companion to Applied Regression. Third. Thousand Oaks CA: Sage. https://socialsciences.mcmaster.ca/jfox/Books/Companion/. McArdle, J. J. 1988. “Dynamic but Structural Equation Modeling of Repeated Measures Data.” In Handbook of Multivariate Experimental Psychology, 2nd Ed, 561–614. Perspectives on Individual Differences. New York, NY, US: Plenum Press. https://doi.org/10.1007/978-1-4613-0893-5_17. Mcardle, J. J., and MARK S. Aber. 1990. “Chapter 5 - Patterns of Change Within Latent Variable Structural Equation Models.” In Statistical Methods in Longitudinal Research, edited by Alexander von Eye, 1:151–224. Statistical Modeling and Decision Science. San Diego: Academic Press. https://doi.org/10.1016/B978-0-12-724960-5.50010-X. McArdle, J. J., and David Epstein. 1987. “Latent Growth Curves Within Developmental Structural Equation Models.” Child Development 58 (1): 110–33. https://doi.org/10.2307/1130295. McArdle, J. J., and John R. Nesselroade. 1994. “Using Multivariate Data to Structure Developmental Change.” In Life-Span Developmental Psychology: Methodological Contributions, 223–67. The West Virginia University Conferences on Life-Span Developmental Psychology. Hillsdale, NJ, US: Lawrence Erlbaum Associates, Inc. Osborne, R. T., and D. E. Suddick. 1972. “A Longitudinal Investigation of the Intellectual Differentiation Hypothesis.” The Journal of Genetic Psychology: Research and Theory on Human Development 121 (1): 83–89. https://doi.org/10.1080/00221325.1972.10533131. Revelle, William. 2021. Psych: Procedures for Psychological, Psychometric, and Personality Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psych. Tierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. Naniar: Data Structures, Summaries, and Visualisations for Missing Data. https://CRAN.R-project.org/package=naniar. Wechsler, David. 1949. Wechsler Intelligence Scale for Children. Wechsler Intelligence Scale for Children. San Antonio, TX, US: Psychological Corporation. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2021. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr. "]]
